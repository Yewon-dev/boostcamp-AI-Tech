{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[ì‹¬í™”ë¬¸ì œ]Transfer Learning & Hyper Parameter Tuning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMUUYcrho3HVNpHtbA/R0Ku",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yewon-dev/boostcamp-AI-Tech/blob/main/TIL/%5B%EC%8B%AC%ED%99%94%EB%AC%B8%EC%A0%9C%5DTransfer_Learning_%26_Hyper_Parameter_Tuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transfer Learning and Hyperparameter Tuning\n",
        "\n",
        "ğŸš€ ëª©í‘œ : CNNì—ì„œ **Transfer Learning** (Fine-Tune, torchvision)ê³¼ **Hyperparameter Tuning**ì„ ìœ„í•œ PyTorch ë° ì¶”ê°€ ë¼ì´ë¸ŒëŸ¬ë¦¬(*Ray Tune*) ì‚¬ìš©ë²• ìµíˆê¸°\n",
        "\n"
      ],
      "metadata": {
        "id": "uJrFT-VV2y-3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **ì‹¤ìŠµ ë‚´ìš©**\n",
        "\n",
        "Fashion-Mnistë¼ëŠ” 10ê°œì˜ ì˜ë¥˜ ì¢…ë¥˜ë¥¼ í¬í•¨í•œ ë°ì´í„°ì…‹ì„ ë¶„ë¥˜í•˜ëŠ” ë”¥ëŸ¬ë‹ ë°©ë²•ë¡  ì¤‘ í•˜ë‚˜ì¸ **Convolution Neural Networks** ëª¨ë¸ì„ **Transfer Learning**ìœ¼ë¡œ í•™ìŠµí•˜ê¸°\n"
      ],
      "metadata": {
        "id": "6gcjrYRV3w3I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "----"
      ],
      "metadata": {
        "id": "YYaBsb0zPO5q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transfer Learning\n",
        "\n",
        "Transfer Learningì€ \"Source Tasks\"ì—ì„œ í•™ìŠµëœ ì§€ì‹ì„ \"Target Task\"ë¡œ ì „ì´í•˜ëŠ” ì ˆì°¨ ë° ë°©ë²•ë¡ ì´ë‹¤."
      ],
      "metadata": {
        "id": "0eFOR_bG4pUp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Source Task ëª¨ë¸ ë§Œë“¤ê¸°"
      ],
      "metadata": {
        "id": "nWAowtYF4pXQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.1 ImangeNet Pretrained Modelì„ torchvidionì—ì„œ ë¶ˆëŸ¬ì˜¤ê¸°\n",
        "\n",
        "- ImageNetì—ì„œ í•™ìŠµëœ **ResNet 18** ë”¥ëŸ¬ë‹ ëª¨ë¸ì„ ë¶ˆëŸ¬ì˜´\n"
      ],
      "metadata": {
        "id": "6Sf-je4P6Lca"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "imagenet_resnet18 = torchvision.models.resnet18(pretrained=True)"
      ],
      "metadata": {
        "id": "F6sA7cNh7wXf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.2 Mnist Pretrained Model ë§Œë“¤ê¸°"
      ],
      "metadata": {
        "id": "u_ap2ZPH7He_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.2.1 Mnist Dataset ë¶ˆëŸ¬ì˜¤ê¸°\n",
        "\n",
        "- Mnist Datasetì€ 0ë¶€í„° 9ê¹Œì§€ ì†ìœ¼ë¡œ ì“°ì¸ 10ê°€ì§€ì˜ í´ë˜ìŠ¤ê°€ ìˆëŠ” ë°ì´í„°ì…‹"
      ],
      "metadata": {
        "id": "nb5P-g3V7HcH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mnist_train = torchvision.datasets.MNIST(root='./mnist', train=True, download=True)\n",
        "mnist_test = torchvision.datasets.MNIST(root='./mnist', train=False, download=True)"
      ],
      "metadata": {
        "id": "u0ah0cyh7s_U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.2.2 Mnistë¥¼ í•™ìŠµí•  CNN ëª¨ë¸ ìƒì„± (ResNet18)"
      ],
      "metadata": {
        "id": "_Jb3ZrDk7HZs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mnist_resnet18 = torchvision.models.resnet18(pretrained=False)"
      ],
      "metadata": {
        "id": "B3m2X67Z8V1O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.2.3 Mnist ë°ì´í„° ë¶„ë¥˜ ResNet18 ëª¨ë¸ì— í•™ìŠµí•˜ê¸°\n",
        "\n",
        "*   torchvision.datasets.ministì˜ ë°ì´í„° íƒ€ì…ì€ PIL Image -> í•™ìŠµ ë•ŒëŠ” Tensor typeìœ¼ë¡œ ë³€í™˜í•´ì•¼ í•œë‹¤\n",
        "*   ì›ë³¸ ì˜ìƒì€ gray scaleì´ì§€ë§Œ ëª¨ë¸ì€ 3ì±„ë„ì´ë¯€ë¡œ gray scaleì„ RGBë¡œ ë³€í™˜í•´ì•¼ í•œë‹¤\n",
        "  - Q. ëª¨ë¸ ì…ë ¥ì„ channel 1ê°œë§Œ ë°›ë„ë¡ ë³€ê²½í•œë‹¤ë©´?\n",
        "  - `mnist_resnet18.conv1 = nn.Conv2d(in_channels = 1, ...)`\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "yT3nP_xC7HW0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "common_transform = torchvision.transforms.Compose([\n",
        "    # grayscaleì˜ 1ì±„ë„ ì˜ìƒì„ 3ì±„ë„ë¡œ ë™ì¼í•œ ê°’ìœ¼ë¡œ í™•ì¥í•¨\n",
        "    torchvision.transforms.Grayscale(num_output_channels=3), \n",
        "    # PIL Imageë¥¼ Tensor typeë¡œ ë³€ê²½í•¨\n",
        "    torchvision.transforms.ToTensor() \n",
        "  ])"
      ],
      "metadata": {
        "id": "_81N9n1X7G57"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(ê²°ê³¼)\n",
        "```\n",
        "ì›ë³¸ <class 'PIL.Image.Image'> (28, 28)\n",
        "ë³€ê²½ë¨ <class 'torch.Tensor'> (3, 28, 28)\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "eQNYRUZu7HT6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "8h0-iuJkWVCO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Xavier Initialization**\n",
        "\n",
        "Xavier Initialization í˜¹ì€ Glorot Initializationë¼ê³ ë„ ë¶ˆë¦¬ëŠ” ì´ˆê¸°í™” ë°©ë²•ì€ **ì´ì „ ë…¸ë“œì™€ ë‹¤ìŒ ë…¸ë“œì˜ ê°œìˆ˜ì— ì˜ì¡´**í•˜ëŠ” ë°©ë²•ì´ë‹¤. Uniform ë¶„í¬ë¥¼ ë”°ë¥´ëŠ” ë°©ë²•ê³¼ Normalë¶„í¬ë¥¼ ë”°ë¥´ëŠ” ë‘ê°€ì§€ ë°©ë²•ì´ ì‚¬ìš©ëœë‹¤.(Glorot & Bengio, AISTATS 2010)\n",
        "\n",
        "- Xavier Normal Initialization\n",
        "$$ Wâˆ¼N(0,Var(W)) $$\n",
        "$$ Var(W)= \\sqrt{\\frac{2}{n_{in}+n_{out}}} $$\n",
        "($n_{in}$ : ì´ì „ layer(input)ì˜ ë…¸ë“œ ìˆ˜, $n_{out}$ : ë‹¤ìŒ layerì˜ ë…¸ë“œ ìˆ˜)\n",
        "\n",
        "- Xavier Uniform Initialization\n",
        "$$ Wâˆ¼U(-\\sqrt{\\frac{6}{n_{in}+n_{out}}},+\\sqrt{\\frac{6}{n_{in}+n_{out}}}) $$\n",
        "($n_{in}$ : ì´ì „ layer(input)ì˜ ë…¸ë“œ ìˆ˜, $n_{out}$ : ë‹¤ìŒ layerì˜ ë…¸ë“œ ìˆ˜)\n",
        "\n",
        "Xaiverí•¨ìˆ˜ëŠ” ë¹„ì„ í˜•í•¨ìˆ˜(ex. sigmoid, tanh)ì—ì„œ íš¨ê³¼ì ì¸ ê²°ê³¼ë¥¼ ë³´ì—¬ì¤€ë‹¤.\n",
        "\n",
        "(ì°¸ê³ ) https://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf"
      ],
      "metadata": {
        "id": "UV0qkb227HRA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n"
      ],
      "metadata": {
        "id": "gVDh80CVPJFB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**tqdm**\n",
        "\n",
        "`from tqdm.notebook import tqdm`\n",
        "\n",
        "- tqdmì´ë¼ëŠ” \"ë°˜ë³µë¬¸\"ì˜ í˜„ì¬ ì§„í–‰ ìƒíƒœë¥¼ progress-barë¡œ ë³´ì—¬ì£¼ëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
        "\n",
        "(ì°¸ê³ ) https://github.com/tqdm/tqdm\n"
      ],
      "metadata": {
        "id": "1OgukRMyEP-U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "XhUvloBdNrbm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**.eval()**\n",
        "\n",
        "\n",
        "`model.eval()`\n",
        "- `nn.Module`ì—ì„œ train timeê³¼ eval timeì—ì„œ ìˆ˜í–‰í•˜ëŠ” ë‹¤ë¥¸ ì‘ì—…ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆë„ë¡ switching í•˜ëŠ” í•¨ìˆ˜\n",
        "- evaluation ê³¼ì •ì—ì„œ ì‚¬ìš©í•˜ì§€ ì•Šì•„ì•¼ í•˜ëŠ” layerë“¤ì„ ì•Œì•„ì„œ offì‹œí‚´"
      ],
      "metadata": {
        "id": "u55exHl6EP7d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "j0Xh4q81NtGG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`for ind, (images, labels) in enumerate(tqdm(dataloaders[phase])):`\n",
        "- progress bar ë‚˜íƒ€ë‚´ê¸° ìœ„í•¨\n",
        "- Q. with ê³¼ pbarì„ ì‚¬ìš©í•˜ìš© epoch, running loss ë“± ë‚˜íƒ€ë‚´ê¸°\n",
        "\n"
      ],
      "metadata": {
        "id": "QhBOnnOnNtBq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "----"
      ],
      "metadata": {
        "id": "ull9YzH9PGml"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.3 Target Task ëª¨ë¸ í•™ìŠµí•˜ê¸°\n"
      ],
      "metadata": {
        "id": "Xo_j1As3PGkL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#### 1.3.1 Fashion-Mnist Dataset ë¶ˆëŸ¬ì˜¤ê¸°\n",
        "\n",
        "- ref - https://github.com/zalandoresearch/fashion-mnist"
      ],
      "metadata": {
        "id": "J2DrJc4UPGhn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fashion_train = torchvision.datasets.FashionMNIST(root='./fashion', train=True, download=True)\n",
        "fashion_test = torchvision.datasets.FashionMNIST(root='./fashion', train=False, download=True)"
      ],
      "metadata": {
        "id": "IWL8nZJ3PrJe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.3.2 Fashion-Mnistë¥¼ í•™ìŠµí•  Source Task ëª¨ë¸ ê°€ì ¸ì˜¤ê¸°\n",
        "- ì•ì„œ (1.2.2)ì—ì„œ imagenetìœ¼ë¡œ ì‚¬ì „ í•™ìŠµëœ ResNet18ì„ ë§Œë“¦"
      ],
      "metadata": {
        "id": "eDgsz27nPefT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "target_model = imagenet_resnet18\n",
        "FASHION_INPUT_NUM = 1\n",
        "FASHION_CLASS_NUM = 10\n",
        "\n",
        "## imagenet_resnet18 ì€ í•„ìš” ì…ë ¥ ì±„ë„ ê°œìˆ˜ê°€ 3, ì˜ˆì¸¡í•˜ëŠ” í´ë˜ìŠ¤ ì¢…ë¥˜ëŠ” 1000ê°€ì§€\n",
        "## Fashion Mnist ë°ì´í„°ëŠ” í•„ìš” ì…ë ¥ ì±„ë„ ê°œìˆ˜ê°€ 1, ë ˆì´ë¸”ì€ 10ê°€ì§€ íƒ€ì…\n",
        "## ë”°ë¼ì„œ Fine-Tuning ì „ì— ëª¨ë¸ êµ¬ì¡° ë³€ê²½\n",
        "target_model.conv1 = torch.nn.Conv2d(FASHION_INPUT_NUM, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
        "target_model.fc = torch.nn.Linear(in_features=512, out_features=FASHION_CLASS_NUM, bias=True)\n"
      ],
      "metadata": {
        "id": "7RO0prNESxwF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.3.3 Fashion-Mnist ë°ì´í„° ë¶„ë¥˜ í•™ìŠµ"
      ],
      "metadata": {
        "id": "8oBTqvtSPect"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ì•ì„œ ì„ ì–¸í•œ ë°ì´í„°ì…‹ì— transform ì¸ìë¥¼ ë„˜ê²¨ì£¼ì\n",
        "fashion_train_transformed = torchvision.datasets.FashionMNIST(root='./fashion', train=True, download=True, transform=common_transform)\n",
        "fashion_test_transformed = torchvision.datasets.FashionMNIST(root='./fashion', train=False, download=True, transform=common_transform)\n",
        "\n",
        "# Mnist Datasetì„ DataLoaderì— ë¶™ì´ê¸°\n",
        "BATCH_SIZE = 64\n",
        "fashion_train_dataloader = torch.utils.data.DataLoader(fashion_train_transformed, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
        "fashion_test_dataloader = torch.utils.data.DataLoader(fashion_test_transformed, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)"
      ],
      "metadata": {
        "id": "bWYBd0EjTdoM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- mnist train ë°ì´í„°ì…‹ì„ ResNet18 ëª¨ë¸ì— í•™ìŠµ"
      ],
      "metadata": {
        "id": "ro3xaJPXT-O7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "LEARNING_RATE = 0.0001 # í•™ìŠµ ë•Œ ì‚¬ìš©í•˜ëŠ” optimizerì˜ í•™ìŠµë¥  ì˜µì…˜ ì„¤ì •\n",
        "NUM_EPOCH = 5 # í•™ìŠµ ë•Œ mnist train ë°ì´í„° ì…‹ì„ ì–¼ë§ˆë‚˜ ë§ì´ í•™ìŠµí• ì§€ ê²°ì •í•˜ëŠ” ì˜µì…˜\n",
        "\n",
        "loss_fn = torch.nn.CrossEntropyLoss() # ë¶„ë¥˜ í•™ìŠµ ë•Œ ë§ì´ ì‚¬ìš©ë˜ëŠ” Cross entropy lossë¥¼ objective functionìœ¼ë¡œ ì‚¬ìš© - https://en.wikipedia.org/wiki/Cross_entropy\n",
        "optimizer = torch.optim.Adam(target_model.parameters(), lr=LEARNING_RATE) # weight ì—…ë°ì´íŠ¸ë¥¼ ìœ„í•œ optimizerë¥¼ Adamìœ¼ë¡œ ì‚¬ìš©í•¨\n"
      ],
      "metadata": {
        "id": "1YWqVaWVTrny"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "[í•™ìŠµì½”ë“œ]"
      ],
      "metadata": {
        "id": "WaB1rqjlUJ7A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "uxKNeRwcWXlR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hyper Parameter Tuning\n",
        "- Ray : Distributed applicationì„ ë§Œë“¤ê¸° ìœ„í•œ í”„ë ˆì„ì›Œí¬\n",
        "- Tune : Ray ì•ˆì— ìˆëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬.\n",
        "\n",
        "(ì°¸ê³ ) https://docs.ray.io/en/master/tune/index.html"
      ],
      "metadata": {
        "id": "0KGniqpKPeTS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Ray Tune ì‚¬ìš©í•˜ê¸°"
      ],
      "metadata": {
        "id": "sfLVCmpCUSFA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Ray í”„ë ˆì„ì›Œí¬ ì„¤ì¹˜\n",
        "```python\n",
        "!pip uninstall -y -q pyarrow\n",
        "!pip install -q -U ray[tune]\n",
        "!pip install -q ray[debug]\n",
        "```"
      ],
      "metadata": {
        "id": "mzWIUIgzUSB5"
      }
    }
  ]
}